# -*- coding: utf-8 -*-
"""fintune_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QKPTdtvc56LjSELymQKXESFg009lmR44
"""

import argparse
import itertools
import os

import matplotlib.pylab as plt
import numpy as np

import tensorflow as tf
import tensorflow_hub as hub
from sklearn.metrics import precision_recall_fscore_support
from config import model_handle_map, model_image_size_map

def build_dataset(data_dir, subset, image_size):
    return tf.keras.preprocessing.image_dataset_from_directory(
        data_dir,
        validation_split=.20,
        subset=subset,
        label_mode="categorical",
        seed=123,
        image_size=image_size,
        batch_size=1
    )

def calculate_metrics(model, val_ds, validation_steps):
    true_labels = []
    predicted_labels = []

    for batch in val_ds.take(validation_steps):
        images, labels = batch
        true_labels.extend(tf.argmax(labels, axis=1).numpy())
        predicted_labels.extend(tf.argmax(model.predict(images), axis=1).numpy())

    precision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')

    return precision, recall, f1_score

def main():
    choices = ['efficientnetv2-s', 'efficientnetv2-m', 'efficientnetv2-l', 'efficientnetv2-s-21k', 'efficientnetv2-m-21k', 'efficientnetv2-l-21k', 'efficientnetv2-xl-21k', 'efficientnetv2-b0-21k', 'efficientnetv2-b1-21k', 'efficientnetv2-b2-21k', 'efficientnetv2-b3-21k', 'efficientnetv2-s-21k-ft1k', 'efficientnetv2-m-21k-ft1k', 'efficientnetv2-l-21k-ft1k', 'efficientnetv2-xl-21k-ft1k', 'efficientnetv2-b0-21k-ft1k', 'efficientnetv2-b1-21k-ft1k', 'efficientnetv2-b2-21k-ft1k', 'efficientnetv2-b3-21k-ft1k', 'efficientnetv2-b0', 'efficientnetv2-b1', 'efficientnetv2-b2', 'efficientnetv2-b3', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'bit_s-r50x1', 'inception_v3', 'inception_resnet_v2', 'resnet_v1_50', 'resnet_v1_101', 'resnet_v1_152', 'resnet_v2_50', 'resnet_v2_101', 'resnet_v2_152', 'nasnet_large', 'nasnet_mobile', 'pnasnet_large', 'mobilenet_v2_100_224', 'mobilenet_v2_130_224', 'mobilenet_v2_140_224', 'mobilenet_v3_small_100_224', 'mobilenet_v3_small_075_224', 'mobilenet_v3_large_100_224', 'mobilenet_v3_large_075_224']
    parser = argparse.ArgumentParser(description="Train a model on a dataset.")
    parser.add_argument("--epochs", type=int, default=1, help="Number of epochs for training.")
    parser.add_argument("--data_dir", type=str, required=True, help="Path to the dataset directory.")
    parser.add_argument("--model_name", type=str, required=True, choices=choices, help="Name of the base model.")
    parser.add_argument("--output_dir", type=str, required=True, help="Path to the output directory for saving figures and the model.")

    args = parser.parse_args()

    model_handle = model_handle_map.get(args.model_name)
    pixels = model_image_size_map.get(args.model_name, 224)
    IMAGE_SIZE = (pixels, pixels)

    BATCH_SIZE = 16

    train_ds = build_dataset(args.data_dir, "training", IMAGE_SIZE)
    class_names = tuple(train_ds.class_names)
    train_size = train_ds.cardinality().numpy()
    train_ds = train_ds.unbatch().batch(BATCH_SIZE)
    train_ds = train_ds.repeat()

    normalization_layer = tf.keras.layers.Rescaling(1. / 255)
    preprocessing_model = tf.keras.Sequential([normalization_layer])

    train_ds = train_ds.map(lambda images, labels: (preprocessing_model(images), labels))

    val_ds = build_dataset(args.data_dir, "validation", IMAGE_SIZE)
    valid_size = val_ds.cardinality().numpy()
    val_ds = val_ds.unbatch().batch(BATCH_SIZE)
    val_ds = val_ds.map(lambda images, labels: (normalization_layer(images), labels))

    do_fine_tuning = False
    model = tf.keras.Sequential([
        tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),
        hub.KerasLayer(model_handle, trainable=do_fine_tuning),
        tf.keras.layers.Dropout(rate=0.2),
        tf.keras.layers.Dense(len(class_names),
                              kernel_regularizer=tf.keras.regularizers.l2(0.0001))
    ])
    model.build((None,) + IMAGE_SIZE + (3,))
    model.summary()
    model.compile(
        optimizer=tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.9),
        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),
        metrics=['accuracy']
    )

    steps_per_epoch = train_size // BATCH_SIZE
    validation_steps = valid_size // BATCH_SIZE

    hist = model.fit(
        train_ds,
        epochs=args.epochs, steps_per_epoch=steps_per_epoch,
        validation_data=val_ds,
        validation_steps=validation_steps
    ).history

    precision, recall, f1_score = calculate_metrics(model, val_ds, validation_steps)

    print("Precision: {:.4f}".format(precision))
    print("Recall: {:.4f}".format(recall))
    print("F1-Score: {:.4f}".format(f1_score))
    plt.figure()
    plt.ylabel("Loss (training and validation)")
    plt.xlabel("Training Steps")
    plt.ylim([0, 2])
    plt.plot(hist["loss"], label='Training Loss')
    plt.plot(hist["val_loss"], label='Validation Loss')
    plt.legend()

    loss_figure_path = os.path.join(args.output_dir, f"{args.model_name}_loss_figure.png")
    plt.savefig(loss_figure_path)

    # Plot and save the Accuracy figure
    plt.figure()
    plt.ylabel("Accuracy (training and validation)")
    plt.xlabel("Training Steps")
    plt.ylim([0, 1])
    plt.plot(hist["accuracy"], label='Training Accuracy')
    plt.plot(hist["val_accuracy"], label='Validation Accuracy')
    plt.legend()

    accuracy_figure_path = os.path.join(args.output_dir, f"{args.model_name}_accuracy_figure.png")
    plt.savefig(accuracy_figure_path)
    # Save the trained model
    saved_model_path = os.path.join(args.output_dir, f"saved_{args.model_name}_model")
    tf.saved_model.save(model, saved_model_path)
    print(f"Model saved at: {saved_model_path}")
    for i in range(5):
        x, y = next(iter(val_ds))
        image = x[0, :, :, :]
        true_index = np.argmax(y[0])

        plt.imshow(image)
        plt.axis('off')
        plt.show()

    # Expand the validation image to (1, 224, 224, 3) before predicting the label
        prediction_scores = model.predict(np.expand_dims(image, axis=0))
        predicted_index = np.argmax(prediction_scores)

        print("True label: " + class_names[true_index])
        print("Predicted label: " + class_names[predicted_index])
        print("Prediction Scores: ", prediction_scores)
        print("\n" + "="*50 + "\n")

if __name__ == "__main__":
    main()